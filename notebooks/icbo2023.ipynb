{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d07d898",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# mOWL: Python library for machine learning with ontologies\n",
    "\n",
    "## Ontology creation:\n",
    "To get started, you can install mOWL using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f642587",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!apt install python3-sklearn python3-sklearn-lib\n",
    "!pip install pystow==0.4.3\n",
    "!pip install mowl-borg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad24b9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "mOWL interfaces the OWL API. For this, we need to interface with the Java Virtual Machine (JVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3268068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mowl\n",
    "mowl.init_jvm(\"10g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a304b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from java.util import HashSet\n",
    "from mowl.owlapi import OWLAPIAdapter\n",
    "from org.semanticweb.owlapi.model import IRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f5cde",
   "metadata": {},
   "source": [
    "## Let's create our first ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = OWLAPIAdapter()\n",
    "ontology = adapter.create_ontology(\"http://mowl/family\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d778ee9b",
   "metadata": {},
   "source": [
    "## Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = adapter.create_class(\"http://Male\")\n",
    "female = adapter.create_class(\"http://Female\")\n",
    "parent = adapter.create_class(\"http://Parent\")\n",
    "person = adapter.create_class(\"http://Person\")\n",
    "mother = adapter.create_class(\"http://Mother\")\n",
    "father = adapter.create_class(\"http://Father\")\n",
    "sibling = adapter.create_class(\"http://Sibling\")\n",
    "brother = adapter.create_class(\"http://Brother\")\n",
    "sister = adapter.create_class(\"http://Sister\")\n",
    "son = adapter.create_class(\"http://Son\")\n",
    "daughter = adapter.create_class(\"http://Daughter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c1de2",
   "metadata": {},
   "source": [
    "## Role names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_child = adapter.create_object_property(\"http://hasChild\")\n",
    "has_parent = adapter.create_object_property(\"http://hasParent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183f6e5",
   "metadata": {},
   "source": [
    "## Individual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "John = adapter.create_individual(\"http://John\")\n",
    "Jane = adapter.create_individual(\"http://Jane\")\n",
    "Robert = adapter.create_individual(\"http://Robert\")\n",
    "Melissa = adapter.create_individual(\"http://Melissa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae84b19",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Axioms\n",
    "\n",
    "Let's create some axioms of the form $A \\sqsubseteq B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a15660",
   "metadata": {},
   "outputs": [],
   "source": [
    "axioms = HashSet()\n",
    "axioms.add(adapter.create_subclass_of(male, person))\n",
    "axioms.add(adapter.create_subclass_of(female, person))\n",
    "axioms.add(adapter.create_subclass_of(parent, person))\n",
    "axioms.add(adapter.create_subclass_of(mother, female))\n",
    "axioms.add(adapter.create_subclass_of(father, male))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2777a",
   "metadata": {},
   "source": [
    "Now, let's create some axioms of the form $A \\sqcap B \\sqsubseteq C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009635d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_and_male = adapter.create_object_intersection_of(parent, male)\n",
    "axioms.add(adapter.create_subclass_of(parent_and_male, father))\n",
    "parent_and_female = adapter.create_object_intersection_of(parent, female)\n",
    "axioms.add(adapter.create_subclass_of(parent_and_female, mother))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349aa157",
   "metadata": {},
   "source": [
    "Now some axioms of the form $A \\sqcup B \\equiv C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_or_female = adapter.create_object_union_of(male, female)\n",
    "axioms.add(adapter.create_equivalent_classes(male_or_female, person))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064c916",
   "metadata": {},
   "source": [
    "One axiom of the form $\\neg A \\equiv  B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a73785",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_male = adapter.create_complement_of(male)\n",
    "axioms.add(adapter.create_equivalent_classes(not_male, female))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b8d1b",
   "metadata": {},
   "source": [
    "One axiom of the form $A \\sqsubseteq \\exists R.B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_child_person = adapter.create_object_some_values_from(has_child, person)\n",
    "axioms.add(adapter.create_subclass_of(parent, has_child_person))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9bb23",
   "metadata": {},
   "source": [
    "And finally, some assertion axioms of the form $C(a)$ and $R(a,b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d94054",
   "metadata": {},
   "outputs": [],
   "source": [
    "axioms.add(adapter.create_class_assertion(father, John))\n",
    "axioms.add(adapter.create_class_assertion(mother, Jane))\n",
    "axioms.add(adapter.create_class_assertion(male, Robert))\n",
    "axioms.add(adapter.create_class_assertion(female, Melissa))\n",
    "axioms.add(adapter.create_object_property_assertion(has_child, John, Robert))\n",
    "axioms.add(adapter.create_object_property_assertion(has_child, Jane, Robert))\n",
    "axioms.add(adapter.create_object_property_assertion(has_child, John, Melissa))\n",
    "axioms.add(adapter.create_object_property_assertion(has_child, Jane, Melissa))\n",
    "adapter.owl_manager.addAxioms(ontology, axioms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_file = os.path.abspath(f'family.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter.owl_manager.saveOntology(ontology, IRI.create('file://'+ont_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f87c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/mowl-tutorial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b43098",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Ontology projections into graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aedf3c",
   "metadata": {
    "cell_marker": "r\"\"\",\n\"\"\""
   },
   "source": [
    "Ontologies are formed by a TBox, an ABox and an RBox. A Knowledge\n",
    "Graph can be easily extracted from the ABox and the RBox. However, to\n",
    "encode the graph representation of the TBox, which is composed by\n",
    "(complex) concept descriptions, many approaches have been developed. In mOWL, we provide some\n",
    "methods that perform ontology projection into graphs:\n",
    "\n",
    "- **Taxonomy projection**: the projection of axioms of the form $A\n",
    "\\sqsubseteq B$ as edges $(A, subclassof, B)$.\n",
    "\n",
    "- **Taxonomy + relations**: the projection of axioms of the form $A\n",
    "\\sqsubseteq B$ and $A \\sqsubseteq \\exists R.B$ as edges $(A,\n",
    "subclassof, B)$ and $(A, R, B)$, respectively.\n",
    "\n",
    "- **DL2Vec projection**\n",
    "\n",
    "- **OWL2Vec projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86e99d",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "\n",
    "import mowl\n",
    "mowl.init_jvm(\"10g\")\n",
    "\n",
    "from mowl.projection import TaxonomyProjector, TaxonomyWithRelationsProjector, DL2VecProjector, OWL2VecStarProjector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eda6c5",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "#from mowl.datasets.builtin import FamilyDataset\n",
    "from mowl.datasets import PathDataset\n",
    "#dataset = FamilyDataset()\n",
    "dataset = PathDataset(\"family.owl\")\n",
    "edges = TaxonomyProjector().project(dataset.ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e189c50",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def nx_network(edges):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    G = nx.DiGraph()\n",
    "    for edge in edges:\n",
    "        src = edge.src.split(\"/\")[-1]\n",
    "        dst = edge.dst.split(\"/\")[-1]\n",
    "        G.add_edge(src, dst)\n",
    "    #nx draw with custom colors\n",
    "    plt.figure(figsize=(5,5))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, edge_color='black', width=1, linewidths=1,\n",
    "            node_size=500, node_color='cyan', alpha=0.9,\n",
    "            labels={node:node for node in G.nodes()})\n",
    "    #nx.draw(G, with_labels=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36a8df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "nx_network(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692241c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dl2vec_proj = DL2VecProjector(bidirectional_taxonomy=True)\n",
    "d2v_edges = dl2vec_proj.project(dataset.ontology, with_individuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dcb08",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "nx_network(d2v_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1fc0c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "owl2vec_proj = OWL2VecStarProjector(bidirectional_taxonomy=True)\n",
    "o2v_edges = owl2vec_proj.project(dataset.ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaa8ec",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "nx_network(o2v_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b525659",
   "metadata": {},
   "source": [
    "# Random-walk-based embeddings of ontologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d9757",
   "metadata": {},
   "source": [
    "After generating the graph, we can embed it in different ways. Two approaches are supported in mOWL: \n",
    "- Embeddings based on random walks\n",
    "- Embeddings based on KGE\n",
    "\n",
    "Let's try the approach with random walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9694db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mowl.walking.deepwalk.model import DeepWalk\n",
    "walker =  DeepWalk(\n",
    "             10, #num_walks,\n",
    "             4, #walk_length,\n",
    "             0.1, #alpha\n",
    "             outfile = \"walks_dw.txt\", # /optional/path/to/save/walks,\n",
    "             workers = 4)\n",
    "walker.walk(o2v_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a3642",
   "metadata": {},
   "source": [
    "## Process the walks using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "walk_corpus_file = walker.outfile\n",
    "sentences = LineSentence(walk_corpus_file)\n",
    "\n",
    "w2v_model = Word2Vec(sentences, vector_size = 2) #vector_size/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51700929",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(\"http://Jane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe8ff1",
   "metadata": {},
   "source": [
    "## Task ðŸš§\n",
    "\n",
    "We will add a new axiom in the ontology:  $hasChild(John,Bob)$. We know that Jhon and Jane already have two children. Can we infer that Bob is also related to Jane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bob = adapter.create_individual(\"http://Bob\")\n",
    "axioms.add(adapter.create_object_property_assertion(has_child, John, Bob))\n",
    "adapter.owl_manager.addAxioms(ontology, axioms)\n",
    "ont_file = os.path.abspath(f'family2.owl')\n",
    "adapter.owl_manager.saveOntology(ontology, IRI.create('file://'+ont_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathDataset(\"family2.owl\")\n",
    "projector = OWL2VecStarProjector(bidirectional_taxonomy=\"True or False\") # YOUR CODE HERE\n",
    "new_edges = projector.project(dataset.ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a62441",
   "metadata": {},
   "outputs": [],
   "source": [
    "walker =  DeepWalk(\n",
    "             \"your number here\", #number of walks,\n",
    "             \"your number here\", #walk length,\n",
    "             \"your number here\", #alpha: restart parameter\n",
    "             outfile = \"walks_dw.txt\", # /optional/path/to/save/walks,\n",
    "             workers = 4)\n",
    "\n",
    "walker.walk(new_edges)\n",
    "walk_corpus_file = walker.outfile\n",
    "sentences = LineSentence(walk_corpus_file)\n",
    "w2v_model = Word2Vec(sentences, vector_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d33bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(\"http://Jane\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db39ee",
   "metadata": {
    "id": "67cacc02",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Use case: Gene-Disease association prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2200f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9703d69b",
    "outputId": "52d1114d-85b6-492e-fd94-2a4883e3798e"
   },
   "outputs": [],
   "source": [
    "# built-in imports\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from mowl.datasets.builtin import GDAMouseDataset\n",
    "from mowl.evaluation.rank_based import EmbeddingsRankBasedEvaluator\n",
    "from mowl.evaluation.base import CosineSimilarity\n",
    "from gensim.models import Word2Vec\n",
    "from mowl.projection import TaxonomyWithRelationsProjector\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings(action='ignore',category=UserWarning,module='gensim')  \n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning,module='gensim') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b554120",
   "metadata": {
    "id": "ef17b662"
   },
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a630981",
   "metadata": {
    "id": "0f7f4e74"
   },
   "source": [
    "Build your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63917192",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "496a47ba",
    "lines_to_next_cell": 2,
    "outputId": "9bb730bd-e98b-4465-fab2-05a2120090ad"
   },
   "outputs": [],
   "source": [
    "from mowl.ontology.extend import insert_annotations\n",
    " \n",
    "diseases_annotations = (\"diseases_annot.tsv\", \"http://has_annotation\", True) \n",
    "genes_annotations = (\"genes_annot.tsv\", \"http://has_annotation\", True) \n",
    "gene_disease_associations = (\"gene_disease_associations.tsv\",\"http://is_associated_with/\", True) \n",
    "\n",
    "annotations = [diseases_annotations , genes_annotations, gene_disease_associations] # There could be more than 1 annotations file. \n",
    "\n",
    "insert_annotations(\"upheno.owl\", annotations, out_file = \"upheno_with_annotations.owl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f3354",
   "metadata": {
    "id": "11e43254"
   },
   "source": [
    "Use the Built-in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60d3e1",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a13439d7"
   },
   "outputs": [],
   "source": [
    "dataset = GDAMouseDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9140e3",
   "metadata": {
    "id": "040c3b7e"
   },
   "source": [
    "The dataset will be downloaded to a folder name `gda_mouse` with the training, validation and testing ontology dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52786c",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "e53eed28",
    "outputId": "0b774d72-3205-47a8-baca-492c1b5efcf0"
   },
   "outputs": [],
   "source": [
    "! ls gda_mouse/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6239e",
   "metadata": {
    "id": "787e2cf9"
   },
   "source": [
    "# Graph-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b44373",
   "metadata": {
    "id": "327f785d"
   },
   "source": [
    " ### Example for two methods: DL2vec and Owl2vec* methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf7483",
   "metadata": {
    "id": "5cf31c82"
   },
   "source": [
    "<font color='blue'><font size=\"4\">1) DL2vec Prediction Method </font></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2770a8",
   "metadata": {
    "id": "9035b59a"
   },
   "source": [
    "1. **Projecting the ontology** \n",
    "- Project the ontology using the DL2Vec Projector class, with the specific rules used to project the ontology. \n",
    "- The outcome of the projection algorithm is an edgelist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a85695",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9d1c7a6f"
   },
   "outputs": [],
   "source": [
    "from mowl.projection.dl2vec.model import DL2VecProjector \n",
    "projector = DL2VecProjector(True)\n",
    "train_edges = projector.project(dataset.ontology)\n",
    "test_edges = projector.project(dataset.testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728608e",
   "metadata": {
    "id": "914d1c77"
   },
   "source": [
    "2. **Generating random walks**\n",
    "- The random walks are generated using the DeepWalk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d569d4",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "99ff6e49"
   },
   "outputs": [],
   "source": [
    "walker = DeepWalk(10, # number of walks per node\n",
    "                  10, # walk length\n",
    "                  0.1, # restart probability\n",
    "                  workers=4, outfile = 'walk',seed=40) # number of threads\n",
    "\n",
    "walks = walker.walk(train_edges)\n",
    "walks_file = walker.outfile\n",
    "sentences = LineSentence(walks_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3e5a0",
   "metadata": {
    "id": "4cdf1ae0"
   },
   "source": [
    "3. **Training the Word2Vec model**\n",
    "- To train the Word2Vec model, we rely on the Gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bfcfc",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "68aa8d8c",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, vector_size=100, epochs = 15, window=5, min_count=1, workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff44f0",
   "metadata": {
    "id": "a390732a"
   },
   "source": [
    "4. **Evaluating the embeddings** \n",
    "- We are going to evaluate the plausibility of an association gene-disease with a gene against all possible diseases and check the rank of the true disease association using CosineSimilarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40132f71",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4c2150ae",
    "outputId": "b557210b-4d2b-4f0f-cbff-61833b71485e"
   },
   "outputs": [],
   "source": [
    "genes, diseases = dataset.evaluation_classes\n",
    "projector = TaxonomyWithRelationsProjector(taxonomy=False,\n",
    "                                           relations=[\"http://is_associated_with\"])\n",
    "\n",
    "vectors = model.wv\n",
    "evaluator = EmbeddingsRankBasedEvaluator(\n",
    "    vectors,\n",
    "    test_edges,\n",
    "    CosineSimilarity,\n",
    "    training_set=train_edges,\n",
    "    head_entities = genes.as_str,\n",
    "    tail_entities = diseases.as_str,\n",
    "    device = 'cpu')\n",
    "\n",
    "\n",
    "evaluator.evaluate(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64b609",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256a9b30",
    "outputId": "31e30808-5e8d-4437-b98d-4c55999cf342"
   },
   "outputs": [],
   "source": [
    "human_disease=[]\n",
    "mouse_genes=[]\n",
    "for classes in vectors.index_to_key:\n",
    "    if 'OMIM' in classes:\n",
    "        human_disease.append(classes)\n",
    "    if classes[7:].isnumeric():\n",
    "        mouse_genes.append(classes)\n",
    "\n",
    "print(f'Number of the disease is {len(human_disease)}, and number of genes is {len(mouse_genes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af94ce1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6a3d852",
    "outputId": "8d1df51a-3491-4ce7-9e87-c710df6d814c"
   },
   "outputs": [],
   "source": [
    "human_disease[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefda54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ece1e2b0",
    "outputId": "7e611889-c9e3-42fe-cb41-48ed175b58cd"
   },
   "outputs": [],
   "source": [
    "mouse_genes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f79c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81bee2a1",
    "outputId": "b9702707-1961-4838-c23b-70bb9d5de906"
   },
   "outputs": [],
   "source": [
    "human_disease_vectors=[]\n",
    "for k in human_disease:\n",
    "    human_disease_vectors.append(vectors[k]) \n",
    "    \n",
    "mouse_genes_vectors=[]\n",
    "for k in mouse_genes:\n",
    "    mouse_genes_vectors.append(vectors[k])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(np.array(human_disease_vectors),np.array(mouse_genes_vectors))\n",
    "\n",
    "print(f\"The dimentions of this matrix is {similarity.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1a259",
   "metadata": {
    "id": "78e26ff6"
   },
   "source": [
    "## Evaluating the predictions to find the most similar genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929f617",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc900f22",
    "lines_to_next_cell": 2,
    "outputId": "3a84d908-6e07-4840-fbbc-538c637e57ef"
   },
   "outputs": [],
   "source": [
    "def find_similar_genes(disease_id, top_k, disease_genes_similarity_matrix, disease_keys, gene_keys):\n",
    "    disease_index = disease_keys.index(disease_id)\n",
    "    prediction_list = np.flip(np.argsort(disease_genes_similarity_matrix[disease_index]))\n",
    "    top_genes = [gene_keys[prediction_list[x]] for x in range(top_k)]\n",
    "    \n",
    "    return top_genes\n",
    "\n",
    "#associations from the file MGI_DO.rpt\n",
    "\n",
    "      \n",
    "#DOID:0080449\tdevelopmental and epileptic encephalopathy 16\tOMIM:615338\tmouse, laboratory\t10090\tTbc1d24\t224617\tMGI:2443456\n",
    "disease_id = 'http://OMIM_615338' \n",
    "top_k = find_similar_genes(disease_id, 5 ,similarity, human_disease, mouse_genes )\n",
    "print(f'The most similar gene to disease {disease_id.split(\"/\")[2]} are: {top_k}')\n",
    "\n",
    "      \n",
    "#DOID:0080436\tdevelopmental and epileptic encephalopathy 4\tOMIM:612164\thuman\t9606\tSTXBP1\t6812\t\n",
    "#DOID:0060309\tsyndromic X-linked intellectual disability\t\thuman\t9606\tHNRNPH2\t3188\t\n",
    "#HNRNPH2\t3188\tHnrnph2\tMGI:1201779\tMP:0001186, MP:0005386, MP:0010771\t      \n",
    "#disease_id = 'http://OMIM_612164' \n",
    "#top_k = find_similar_genes(disease_id, 5 ,similarity, human_disease, mouse_genes )\n",
    "#print(f'The most similar gene to disease {disease_id.split(\"/\")[2]} are: {top_k}')\n",
    "\n",
    "\n",
    "#OMIM_181500 : schizophrenia : DOID:5419\tOMIM:181500\tmouse, laboratory\t10090\tMagi2\t50791\tMGI:1354953\n",
    "#disease_id = 'http://OMIM_181500' \n",
    "#top_k = find_similar_genes(disease_id, 5 ,similarity, human_disease, mouse_genes )\n",
    "#print(f'The most similar gene to disease {disease_id.split(\"/\")[2]} are: {top_k}')\n",
    "      \n",
    "\n",
    "#OMIM_615643 : neurodegeneration with brain iron accumulation 6\n",
    "#DOID:0110740\tOMIM:615643\tmouse, laboratory\t10090\tCoasy\t71743\tMGI:1918993\n",
    "#disease_id = 'http://OMIM_615643' \n",
    "#top_k = find_similar_genes(disease_id, 5 ,similarity, human_disease, mouse_genes )\n",
    "#print(f'The most similar gene to disease {disease_id.split(\"/\")[2]} are: {top_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80405e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaenNY_VqKy2",
    "lines_to_next_cell": 2,
    "outputId": "059a3c80-6cd6-4b81-f750-980fac3e158d"
   },
   "outputs": [],
   "source": [
    "def find_similar_genes(disease_id, top_k, disease_genes_similarity_matrix, disease_keys, gene_keys):\n",
    "    disease_index = disease_keys.index(disease_id)\n",
    "    prediction_list = np.flip(np.argsort(disease_genes_similarity_matrix[disease_index]))\n",
    "    top_genes = [gene_keys[prediction_list[x]] for x in range(top_k)]\n",
    "    \n",
    "    return top_genes\n",
    "\n",
    "disease_id = 'http://OMIM_615643' \n",
    "top_k = find_similar_genes(disease_id, 5 ,similarity, human_disease, mouse_genes )\n",
    "print(f'The most similar gene to disease {disease_id.split(\"/\")[2]} are: {top_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc97ce0",
   "metadata": {
    "id": "4125dc4b"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2771c0c",
   "metadata": {
    "id": "04925b9e"
   },
   "source": [
    "# **Task 1 :**\n",
    "\n",
    "<div class=\"alert alert-block alert-success\" , color ='grreen'> \n",
    "\n",
    "<font size=\"4\"> \n",
    "    Predict the <font color='SteelBlue'>top 10 similar genes</font> to \n",
    "    diabetes mellitus disease OMIM ID: <font color='Tomato'>http://OMIM_608036</font>\n",
    "    using <font color='red'>OWL2vec*</font> prediction method\n",
    "\n",
    "</font>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7a98c",
   "metadata": {
    "id": "8dc67f6c"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Follow the <b>TODO</b> interactions to modify the script, and the rest should be the same you just need to run the cell to execute the code.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50569276",
   "metadata": {
    "id": "a15b208a"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c571437",
   "metadata": {
    "id": "eafd7415"
   },
   "source": [
    "<font color='blue'><font size=\"4\">2) OWL2vec* Prediction Method </font></font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31588e5",
   "metadata": {
    "id": "56cdce23"
   },
   "source": [
    "1. **Projecting the ontology** \n",
    "- Project the ontology using the OWL2Vec* Projector class, with the specific rules used to project the ontology. \n",
    "- The outcome of the projection algorithm is an edgelist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd42608",
   "metadata": {
    "id": "5e6fa077"
   },
   "outputs": [],
   "source": [
    "from mowl.projection import #TODO: import the appropriate function (refer to https://mowl.readthedocs.io/en/latest/api/projection/index.html)\n",
    "dataset = GDAMouseDataset()\n",
    "projector = OWL2VecStarProjector(True)\n",
    "train_edges = projector.project(dataset.ontology)\n",
    "test_edges = projector.project(dataset.testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a2493",
   "metadata": {
    "id": "927c3cd8"
   },
   "source": [
    "2. **Generating random walks**\n",
    "- The random walks are generated using the DeepWalk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe35eee",
   "metadata": {
    "id": "daf9ba01"
   },
   "outputs": [],
   "source": [
    "walker = DeepWalk( ,#TODO: add the number of walks per node\n",
    "                   ,#TODO: add the walk length\n",
    "                  workers=4, # number of threads\n",
    "                  outfile = , #TODO: add the name of the output file for the walks\n",
    "                  seed=40) #fix the random seed \n",
    "\n",
    "walks = walker.walk(train_edges)\n",
    "walks_file = walker.outfile\n",
    "sentences = LineSentence(walks_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea59dab",
   "metadata": {
    "id": "4b3aa6e5"
   },
   "source": [
    "3. **Training the Word2Vec model**\n",
    "- To train the Word2Vec model, we rely on the Gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34063d",
   "metadata": {
    "id": "56fe1600",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, \n",
    "                 vector_size= , #TODO: add the size of the vector\n",
    "                 epochs = ,     #TODO: update the number of training epochs\n",
    "                 window=5, min_count=1, workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78bdd2",
   "metadata": {
    "id": "1641c9c3"
   },
   "source": [
    "4. **Evaluating the embeddings** \n",
    "- We are going to evaluate the plausibility of an association gene-disease with a gene against all possible diseases and check the rank of the true disease association using CosineSimilarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6c1d2",
   "metadata": {
    "id": "f805927d"
   },
   "outputs": [],
   "source": [
    "genes, diseases = dataset.evaluation_classes\n",
    "projector = TaxonomyWithRelationsProjector(taxonomy=False,\n",
    "                                           relations=[\"http://is_associated_with\"])\n",
    "\n",
    "vectors = model.wv\n",
    "evaluator = EmbeddingsRankBasedEvaluator(\n",
    "    vectors,\n",
    "    test_edges,\n",
    "    CosineSimilarity,\n",
    "    training_set=train_edges,\n",
    "    head_entities = genes.as_str,\n",
    "    tail_entities = diseases.as_str,\n",
    "    device = 'cuda')\n",
    "\n",
    "evaluator.evaluate(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07969a72",
   "metadata": {
    "id": "69f2a127"
   },
   "outputs": [],
   "source": [
    "human_disease=[]\n",
    "mouse_genes=[]\n",
    "for classes in vectors.index_to_key:\n",
    "    if 'OMIM' in classes:\n",
    "        human_disease.append(classes)\n",
    "    if classes[7:].isnumeric():\n",
    "        mouse_genes.append(classes)\n",
    "\n",
    "print(f'Number of the disease is {len(human_disease)}, and number of genes is {len(mouse_genes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e658c",
   "metadata": {
    "id": "f7cfe9e6"
   },
   "outputs": [],
   "source": [
    "human_disease_vectors=[]\n",
    "for k in human_disease:\n",
    "    human_disease_vectors.append(vectors[k]) \n",
    "    \n",
    "mouse_genes_vectors=[]\n",
    "for k in mouse_genes:\n",
    "    mouse_genes_vectors.append(vectors[k])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(np.array(human_disease_vectors),np.array(mouse_genes_vectors))\n",
    "\n",
    "print(\"the dimentions of this matrix is \", similarity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07033a12",
   "metadata": {
    "id": "4acede44"
   },
   "source": [
    "## Evaluating the predictions to find the most similar genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbeb59",
   "metadata": {
    "id": "d7452778"
   },
   "outputs": [],
   "source": [
    "def find_similar_genes(disease_id, top_k, disease_genes_similarity_matrix, disease_keys, gene_keys):\n",
    "    disease_index = disease_keys.index(disease_id)\n",
    "    prediction_list = np.flip(np.argsort(disease_genes_similarity_matrix[disease_index]))\n",
    "    top_genes = [gene_keys[prediction_list[x]] for x in range(top_k)]\n",
    "    \n",
    "    return top_genes\n",
    "\n",
    "  \n",
    "\n",
    "disease_id = #TODO: write the disease OMIM ID\n",
    "\n",
    "number_of_genes =  #TODO: number of genes to be ranked\n",
    "\n",
    "top_k = find_similar_genes( , #TODO: disease OMIM ID\n",
    "                            , #TODO: number of genes \n",
    "                           similarity, \n",
    "                           human_disease, \n",
    "                           mouse_genes)\n",
    "\n",
    "print(f'The top {number_of_genes} most similar gene to disease {disease_id.split(\"/\")[2]} are:')\n",
    "\n",
    "for idx, genes in enumerate(top_k):\n",
    "    print(f\" Gene in Rank {idx+1} is : {top_k[idx]}\")\n",
    "\n",
    "\n",
    "\n",
    "                                                                                                               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d38bf1",
   "metadata": {
    "id": "342cbd65-5035-4d51-9450-ae62bbf5895b"
   },
   "source": [
    "# Model-theoretic ontology embedding methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde231b",
   "metadata": {
    "id": "ba40a869-6133-4f21-9476-61d491a4c02d"
   },
   "source": [
    "## EL-Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4924e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVLfD_DmdQNz",
    "outputId": "b8d3e91a-a9bc-4bef-c4cb-7a42a7e90ed1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4e593",
   "metadata": {
    "id": "0bfb2030-f007-4973-a40d-9b56696be17e"
   },
   "source": [
    "Import MOWL library and ELEmbedding model base classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937dd28",
   "metadata": {
    "id": "48048228-53d9-496f-ba8f-f81a0af469a8",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import mowl\n",
    "mowl.init_jvm(\"10g\")\n",
    "\n",
    "from mowl.models.elembeddings.module import ELEmModule\n",
    "from mowl.base_models.elmodel import EmbeddingELModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f4f78",
   "metadata": {
    "id": "e7b2f876-b08d-47c6-8fd9-fc1a48a94d99"
   },
   "source": [
    "Define the model and training strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82ea53",
   "metadata": {
    "id": "36cc9569-a293-4333-817a-077cae347403"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "class ELEmbeddings(EmbeddingELModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 embed_dim=50,\n",
    "                 margin=0,\n",
    "                 reg_norm=1,\n",
    "                 learning_rate=0.001,\n",
    "                 epochs=1000,\n",
    "                 batch_size=4096 * 8,\n",
    "                 model_filepath=None,\n",
    "                 device='cpu'\n",
    "                 ):\n",
    "        super().__init__(dataset, batch_size, extended=True, model_filepath=model_filepath)\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.margin = margin\n",
    "        self.reg_norm = reg_norm\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self._loaded = False\n",
    "        self._loaded_eval = False\n",
    "        self.extended = False\n",
    "        self.init_model()\n",
    "\n",
    "    def init_model(self):\n",
    "        self.model = ELEmModule(\n",
    "            len(self.class_index_dict),  # number of ontology classes\n",
    "            len(self.object_property_index_dict),  # number of ontology object properties\n",
    "            embed_dim=self.embed_dim,\n",
    "            margin=self.margin\n",
    "        ).to(self.device)\n",
    "\n",
    "    def train(self, checkpoint=1):\n",
    "        optimizer = th.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for epoch in trange(self.epochs):\n",
    "            self.model.train()\n",
    "\n",
    "            train_loss = 0\n",
    "            loss = 0\n",
    "\n",
    "            # Notice how we use the ``training_datasets`` variable directly\n",
    "            # and every element of it is a pair (GCI name, GCI tensor data).\n",
    "            for gci_name, gci_dataset in self.training_datasets.items():\n",
    "                if len(gci_dataset) == 0:\n",
    "                    continue\n",
    "                loss += th.mean(self.model(gci_dataset[:], gci_name))\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().item()\n",
    "            th.save(self.model.state_dict(), self.model_filepath)\n",
    "            if (epoch + 1) % checkpoint == 0:\n",
    "                print(f'\\nEpoch {epoch}: Train loss: {train_loss:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e9661",
   "metadata": {
    "id": "76b69df0-c537-49ae-baf5-57d191bba9bb"
   },
   "source": [
    "Create the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274535f",
   "metadata": {
    "id": "f85efc62-cc5f-4c2d-9560-ab388c7c4bf5"
   },
   "outputs": [],
   "source": [
    "from mowl.datasets import PathDataset\n",
    "\n",
    "family_dataset = PathDataset('family.owl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ba417",
   "metadata": {
    "id": "c35a2aa7-862f-40b2-a6c5-a579aa2a1f2d"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238924a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb3b5b25-69e0-4783-b7ee-a488e13a804d",
    "outputId": "1f455631-50c7-4fca-ce0c-4bfab93a2f44"
   },
   "outputs": [],
   "source": [
    "elembeddings = ELEmbeddings(family_dataset,\n",
    "                     embed_dim=2,\n",
    "                     margin=0.1,\n",
    "                     reg_norm=1,\n",
    "                     learning_rate=0.01,\n",
    "                     epochs=1000,\n",
    "                     batch_size=2,\n",
    "                     model_filepath=None,\n",
    "                     device='cpu')\n",
    "\n",
    "elembeddings.train(checkpoint=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a96fba",
   "metadata": {
    "id": "4cfe4d5c-76b4-404b-83a3-649e6c5defd0"
   },
   "source": [
    "Extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a98ef1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0f803cb-5a69-435d-a7a4-cd2783d6dc3e",
    "outputId": "25166689-4c8a-439d-e5be-0ef4c5afb90a"
   },
   "outputs": [],
   "source": [
    "embeds = elembeddings.model.class_embed.weight.cpu().detach().numpy()\n",
    "rs = np.abs(elembeddings.model.class_rad.weight.cpu().detach().numpy())\n",
    "classes = list(elembeddings.class_index_dict.keys())\n",
    "rs, embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2379cb0",
   "metadata": {
    "id": "8311f27e-0620-47d7-b176-a4b9d228447b"
   },
   "source": [
    "Plot embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634652df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "027e5f57-b800-4272-8d16-9f44fa494d64",
    "lines_to_next_cell": 2,
    "outputId": "8c7dbdab-758a-46ed-adf4-2fee5d122ae1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = [item.split('/')[-1] for item in classes]\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "fig, ax =  plt.subplots()\n",
    "plt.axis('equal')\n",
    "ax.set_xlim(-5, 4)\n",
    "ax.set_ylim(-3, 4)\n",
    "for i in range(embeds.shape[0]):\n",
    "    if classes[i].endswith('hing'):\n",
    "        continue\n",
    "    x, y = embeds[i, 0], embeds[i, 1]\n",
    "    r = rs[i]\n",
    "    ax.add_artist(plt.Circle(\n",
    "        (x, y), r, fill=False, edgecolor=colors[i % len(colors)], label=classes[i]))\n",
    "    ax.annotate(classes[i], xy=(x, y + r + 0.03), fontsize=10, ha=\"center\", color=colors[i % len(colors)])\n",
    "ax.grid(True)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9a4d9",
   "metadata": {
    "id": "277e3054-e181-4b8f-84fd-79e52c5623fd",
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}